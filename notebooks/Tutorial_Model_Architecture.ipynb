{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5]], shape=(1, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = [[2],[1]]\n",
    "m = tf.matmul(tf.transpose(x),x)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir(\"../src/models/\")\n",
    "import atom\n",
    "from atom import interatomic_distances\n",
    "from atom import site_rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read tfrecord ###\n",
    "def read_tfrecord(tfrecord_file, train_position, batch_size = 100, num_epochs = None, shuffle = False, buffer_size = 99000,cutoff = 20, step=0.2):\n",
    "    def parser(record):\n",
    "        featnames = ['elements'] + [train_position] + ['targets']\n",
    "        feattypes = [tf.int64, tf.float32, tf.float32]\n",
    "        features = { featname :tf.FixedLenFeature([], tf.string) for featname in featnames}\n",
    "        tfrecord_features = tf.parse_single_example(record, features=features, name='features')\n",
    "        newfeatures = {}\n",
    "        for featname, feattype in zip(featnames, feattypes):\n",
    "            feat = tf.decode_raw(tfrecord_features[featname], feattype)\n",
    "            if featname == 'positions' or featname == 'mmffpositions' or featname == \"positions1\" or featname == \"positions2\":\n",
    "                feat = tf.reshape(feat, (-1, 3))\n",
    "            if featname == 'targets':\n",
    "                feat = tf.reshape(feat, (15, 1))\n",
    "            newfeatures[featname] = feat\n",
    "        return newfeatures\n",
    "    df = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    df = df.map(parser)\n",
    "    if shuffle != False:\n",
    "        df = df.shuffle(buffer_size = buffer_size)\n",
    "    df = df.repeat(num_epochs)\n",
    "    df = df.padded_batch(batch_size= batch_size,padded_shapes={\"elements\":[None,],train_position:[None,3],\"targets\":[15,1]},padding_values=None)\n",
    "    iterator = df.make_one_shot_iterator()\n",
    "    features = iterator.get_next()\n",
    "    \n",
    "    distances = interatomic_distances(tf.cast(features[train_position], tf.float32))\n",
    "    rdf = site_rdf(distances, cutoff=cutoff, step=step, width=1)\n",
    "\n",
    "    features[\"rdf\"] = rdf\n",
    "    return iterator, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing should be noted is that when enable eager, tf.data.Dataset.make_initializable_iterator can't be used <br>\n",
    "Use make_one_shot_iterator instead, which generate a iterator with all information of dataset<br>\n",
    "Use iterator.get_next() can get the first element in iterator<br>\n",
    "If you want to go through all of the data, just use for loop and contain get_next in loop <br>\n",
    "With no eager on, don't need to contain get_next in loop <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "### example ###\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "### Use for loop to go through all instances, remember contain get_next in loop ###\n",
    "for i in range(10):\n",
    "    next_element = iterator.get_next()\n",
    "    print(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_file = \"../../data/external/qm9mmff/train_new.tfrecord\"\n",
    "train_position = \"positions\"\n",
    "### now train_features is only the first instance of iterator\n",
    "iterator, train_features = read_tfrecord(tfrecord_file, train_position, batch_size = 10, num_epochs = 1, shuffle = False, buffer_size = 99000,cutoff = 3, step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=80, shape=(10, 25), dtype=int64, numpy=\n",
       "array([[6, 6, 6, 6, 6, 7, 6, 7, 8, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 6, 8, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 7, 6, 8, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [8, 6, 6, 8, 6, 6, 8, 6, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 8, 6, 6, 8, 6, 6, 6, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 6, 7, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 6, 7, 6, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1],\n",
       "       [6, 7, 6, 6, 6, 8, 6, 6, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0]])>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2111, shape=(2, 30), dtype=float32, numpy=\n",
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.19509683e-36, 4.20253336e-31,\n",
       "        5.06823009e-26, 2.09623642e-21, 2.97345457e-17, 1.44650622e-13,\n",
       "        2.41332371e-10, 1.38086264e-07, 2.70971286e-05, 1.82361354e-03,\n",
       "        4.20901105e-02, 3.33169371e-01, 9.04456973e-01, 8.42070758e-01,\n",
       "        2.68872917e-01, 2.94430852e-02, 1.10575103e-03, 1.42419467e-05,\n",
       "        6.29094359e-08, 9.53030432e-11, 4.95139343e-14, 8.82257027e-18,\n",
       "        5.39126677e-22, 1.12988324e-26, 8.12091859e-32, 2.00182952e-37,\n",
       "        0.00000000e+00, 0.00000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[\"elements\"]\n",
    "### rdf is the distance input after Gaussian expansion with cutoff 3A and 0.1 step ###\n",
    "train_features[\"rdf\"][0][0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters ###\n",
    "n_basis = 256\n",
    "n_factors = 60\n",
    "n_interactions = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = train_features[\"elements\"]\n",
    "C = train_features[\"rdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input charge vetor shape:\n",
      "[10, 25]\n",
      "Input distance vector shape:\n",
      "[10, 25, 25, 30]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input charge vetor shape:\")\n",
    "print(Z.get_shape().as_list())\n",
    "print(\"Input distance vector shape:\")\n",
    "print(C.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.]\n",
      " [36.]\n",
      " [36.]\n",
      " [36.]\n",
      " [36.]\n",
      " [42.]\n",
      " [36.]\n",
      " [42.]\n",
      " [48.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]], shape=(25, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Set mask ###\n",
    "mask = tf.cast(tf.expand_dims(Z, 1) * tf.expand_dims(Z, 2), tf.float32)\n",
    "mask = tf.matrix_set_diag(mask, tf.zeros_like(tf.matrix_diag_part(mask)))\n",
    "mask = tf.expand_dims(mask, -1)\n",
    "print(mask[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask will be used to time the interaction term, thus only neighbor atom (not itself or 0) should be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define fully connected layers, and useful functions ###\n",
    "def shape(x):\n",
    "    if isinstance(x, tf.Tensor):\n",
    "        return x.get_shape().as_list()\n",
    "    return np.shape(x)\n",
    "\n",
    "def glorot_uniform(shape, dtype, partition_info=None):\n",
    "    if not dtype.is_floating:\n",
    "        raise ValueError(\"Expected floating point type, got %s.\" % dtype)\n",
    "\n",
    "    n_in = np.prod(shape[:-1])\n",
    "    n_out = shape[-1]\n",
    "\n",
    "    r = tf.cast(tf.sqrt(6. / (n_in + n_out)), tf.float32)\n",
    "    return tf.random_uniform(shape, -r, r, dtype=dtype)\n",
    "\n",
    "def dense(x, n_out,nonlinearity=None,use_bias=True,\n",
    "          weight_init=glorot_uniform,bias_init=tf.constant_initializer(0.),trainable=True,\n",
    "          scope=None, reuse=False, name='Dense'):\n",
    "    x_shape = shape(x)\n",
    "    ndims = len(x_shape)\n",
    "    n_in = x_shape[-1]\n",
    "    with tf.variable_scope(scope, default_name=name, values=[x],\n",
    "                           reuse=reuse) as scope:\n",
    "        # reshape for broadcasting\n",
    "        xr = tf.reshape(x, (-1, n_in))\n",
    "        W = tf.get_variable('W', shape=(n_in, n_out),\n",
    "                            initializer=weight_init,\n",
    "                            trainable=trainable)\n",
    "        tf.add_to_collection(tf.GraphKeys.WEIGHTS, W)\n",
    "        tf.summary.histogram('W', W)\n",
    "\n",
    "        y = tf.matmul(xr, W)\n",
    "\n",
    "        if use_bias:\n",
    "            b = tf.get_variable('b', shape=(n_out,),\n",
    "                                initializer=bias_init,\n",
    "                                trainable=trainable)\n",
    "            tf.add_to_collection(tf.GraphKeys.BIASES, b)\n",
    "            tf.summary.histogram('b', b)\n",
    "            y += b\n",
    "\n",
    "        if nonlinearity:\n",
    "            y = nonlinearity(y)\n",
    "\n",
    "        new_shape = tf.concat([tf.shape(x)[:ndims - 1], [n_out]], axis=0)\n",
    "        y = tf.reshape(y, new_shape)\n",
    "\n",
    "        tf.summary.histogram('activations', y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initilization of charge vector ###\n",
    "### generate one hot encoding for input charge vector ###\n",
    "I = np.eye(20).astype(np.float32)\n",
    "ZZ = tf.nn.embedding_lookup(I, Z)\n",
    "r = tf.sqrt(1. / tf.sqrt(float(n_basis)))\n",
    "X = dense(ZZ, n_basis, use_bias=False, weight_init=tf.random_normal_initializer(stddev=r),scope = \"initial_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial embedding shape: No bias, weight_init = tf.random_normal_initializer(stddev=r)\n",
      "(10, 25, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial embedding shape: No bias, weight_init = tf.random_normal_initializer(stddev=r)\")\n",
    "print(X.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'initial_embedding/W:0' shape=(20, 256) dtype=float32, numpy=\n",
       " array([[ 0.11875952, -0.23058635,  0.08487264, ..., -0.04433521,\n",
       "          0.24136327,  0.07745977],\n",
       "        [ 0.00947792,  0.24367547, -0.55862415, ..., -0.2738677 ,\n",
       "         -0.36462742, -0.31353384],\n",
       "        [-0.3552743 , -0.20566714, -0.11362048, ...,  0.06695532,\n",
       "          0.10689724, -0.22511972],\n",
       "        ...,\n",
       "        [-0.12171436, -0.00504464,  0.0300582 , ...,  0.01375662,\n",
       "         -0.19546737, -0.1701538 ],\n",
       "        [-0.3456712 , -0.53926086,  0.25564918, ...,  0.16367278,\n",
       "          0.5340095 , -0.08660128],\n",
       "        [-0.3445733 , -0.0302835 , -0.25506225, ...,  0.19609487,\n",
       "         -0.6742876 ,  0.4401804 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Initial embedding weights ###\n",
    "tf.get_collection(tf.GraphKeys.WEIGHTS, \"initial_embedding\")\n",
    "tf.get_collection(tf.GraphKeys.BIASES, \"initial_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initilization of distance vector ###\n",
    "fC = dense(C, n_factors, use_bias=True,scope = \"initial_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial distance shape: bias=True,weight_init=glorot_uniform,bias_init=tf.constant_initializer(0.)\n",
      "(10, 25, 25, 60)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial distance shape: bias=True,weight_init=glorot_uniform,bias_init=tf.constant_initializer(0.)\")\n",
    "print(fC.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'initial_distance/W:0' shape=(30, 60) dtype=float32, numpy=\n",
       " array([[-0.22729053, -0.10617097,  0.21834058, ..., -0.14167622,\n",
       "          0.1729415 ,  0.21726528],\n",
       "        [ 0.12840334, -0.234496  , -0.25388485, ..., -0.01537693,\n",
       "         -0.13276678,  0.10266411],\n",
       "        [-0.19654092, -0.13293108, -0.00402111, ..., -0.2257106 ,\n",
       "          0.03505188,  0.14333695],\n",
       "        ...,\n",
       "        [-0.17199841,  0.03974071, -0.1038437 , ...,  0.07267618,\n",
       "          0.17445144,  0.25768486],\n",
       "        [-0.25053346, -0.21315396,  0.22920305, ..., -0.05761026,\n",
       "         -0.19399254,  0.11422804],\n",
       "        [-0.05319934,  0.14005   , -0.11742249, ...,  0.11760095,\n",
       "         -0.05191755,  0.19052589]], dtype=float32)>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'initial_distance/b:0' shape=(60,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Initial distance weights ###\n",
    "tf.get_collection(tf.GraphKeys.WEIGHTS, \"initial_distance\")\n",
    "tf.get_collection(tf.GraphKeys.BIASES, \"initial_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interaction Blocks ###\n",
    "### Useful functions ###\n",
    "def _softplus(x):\n",
    "    return tf.log1p(tf.exp(x))\n",
    "\n",
    "def shifted_softplus(x):\n",
    "    \"\"\"\n",
    "    Softplus nonlinearity shifted by -log(2) such that shifted_softplus(0.) = 0.\n",
    "\n",
    "    y = log(0.5e^x + 0.5)\n",
    "    \n",
    "    14 is the cutoff for exposion (if element in x > 14, it will be replaces by 0)\n",
    "    \n",
    "    _softplus(tf.where(x < 14., x, tf.zeros_like(x))) almost always less than 14\n",
    "\n",
    "    \"\"\"\n",
    "    y = tf.where(x < 14., _softplus(tf.where(x < 14., x, tf.zeros_like(x))), x)\n",
    "    return y - tf.log(2.)\n",
    "def masked_reduce(x, mask=None, axes=None,\n",
    "                  reduce_op=tf.reduce_sum,\n",
    "                  keep_dims=False,\n",
    "                  scope=None, name='masked_reduce'):\n",
    "    scope_vars = [x]\n",
    "    if mask is not None:\n",
    "        scope_vars.append(mask)\n",
    "\n",
    "    with tf.variable_scope(scope, default_name=name,\n",
    "                           values=scope_vars) as scope:\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask > 0, tf.float32)\n",
    "            x *= mask\n",
    "\n",
    "        y = reduce_op(x, axes, keep_dims)\n",
    "\n",
    "    return y\n",
    "\n",
    "def masked_sum(x, mask=None, axes=None,\n",
    "               keep_dims=False,\n",
    "               scope=None, name='masked_sum'):\n",
    "    return masked_reduce(x, mask, axes, tf.reduce_sum,\n",
    "                         keep_dims, scope, name)\n",
    "\n",
    "\n",
    "def masked_mean(x, mask=None, axes=None,\n",
    "                keep_dims=False,\n",
    "                scope=None, name='masked_mean'):\n",
    "    if mask is None:\n",
    "        mred = masked_reduce(x, mask, axes, tf.reduce_mean,\n",
    "                             keep_dims, scope, name)\n",
    "    else:\n",
    "        msum = masked_reduce(x, mask, axes, tf.reduce_sum,\n",
    "                             keep_dims, scope, name)\n",
    "        mask = tf.cast(mask > 0, tf.float32)\n",
    "        N = tf.reduce_sum(mask, axes, keep_dims)\n",
    "        N = tf.maximum(N, 1)\n",
    "        mred = msum / N\n",
    "    return mred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse = None\n",
    "for i in range(n_interactions):\n",
    "    ### increase initial embedding dimension ###\n",
    "    tmp = tf.expand_dims(X, 1)\n",
    "    ### one atom-wise layer ###\n",
    "    fX = dense(tmp, n_factors, use_bias=True, scope='in2fac' + str(i), reuse=reuse)\n",
    "    ### get interaction term\n",
    "    fVj = fX * fC\n",
    "    Vj = dense(fVj, n_basis, use_bias=False, weight_init=tf.constant_initializer(0.0),\n",
    "               scope='fac2out' + str(i), reuse=reuse)\n",
    "    Vj = shifted_softplus(Vj)\n",
    "    ### use mask to remove non neighbor atoms and sum ###\n",
    "    V = masked_sum(Vj, mask, axes=2)\n",
    "    ### update atom embedding ###\n",
    "    X += V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final atom embedding for first molecule\n",
      "tf.Tensor(\n",
      "[[-0.10555546  0.14823608 -0.18198036 ... -0.04932855 -0.17273639\n",
      "  -0.13344556]\n",
      " [-0.10555546  0.14823608 -0.18198036 ... -0.04932855 -0.17273639\n",
      "  -0.13344556]\n",
      " [-0.10555546  0.14823608 -0.18198036 ... -0.04932855 -0.17273639\n",
      "  -0.13344556]\n",
      " ...\n",
      " [ 0.11875952 -0.23058635  0.08487264 ... -0.04433521  0.24136327\n",
      "   0.07745977]\n",
      " [ 0.11875952 -0.23058635  0.08487264 ... -0.04433521  0.24136327\n",
      "   0.07745977]\n",
      " [ 0.11875952 -0.23058635  0.08487264 ... -0.04433521  0.24136327\n",
      "   0.07745977]], shape=(25, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final atom embedding for first molecule\")\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vj dimension:\n",
      "(10, 25, 25, 256)\n",
      "V dimension: neighbour effects has been summed for each atom\n",
      "(10, 25, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vj dimension:\")\n",
    "print(Vj.get_shape())\n",
    "print(\"V dimension: neighbour effects has been summed for each atom\")\n",
    "print(V.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is just a showcase and there is no training process, Vj is a zero matrix since weight_init using constant zero. However, with training process continue, weight in scope fac2out will be trained and Vj will be generated and X will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Output Layer ###\n",
    "o1 = dense(X, n_basis // 2, nonlinearity=tf.nn.tanh)\n",
    "yi = dense(o1, 1, weight_init=tf.constant_initializer(0.0), use_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final atomic energy\n",
      "(10, 25, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final atomic energy\")\n",
    "print(yi.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization ###\n",
    "### std, mu from training set ###\n",
    "mu = -4.24368628211098\n",
    "std = 0.18926335325096477\n",
    "yi = yi * std + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add Atom Reference ###\n",
    "### atom reference from QM calculation ###\n",
    "atom_ref = np.load(\"../../data/raw/atomrefs.txt.npz\")\n",
    "atom_ref = atom_ref[\"atom_ref\"][:,1:2]\n",
    "atom_ref = tf.constant(atom_ref[0:10],tf.float32)\n",
    "if atom_ref != 0.000:\n",
    "    E0i = tf.nn.embedding_lookup(atom_ref, Z)\n",
    "    yi += E0i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Molecular Energy ###\n",
    "### sum all molecules (non padded one) ###\n",
    "atom_mask = tf.expand_dims(Z, -1)\n",
    "mask = tf.cast(atom_mask > 0, tf.float32)\n",
    "y = tf.reduce_sum(yi * mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final energy:\n",
      "(10, 1)\n",
      "tf.Tensor(\n",
      "[[-11373.443]\n",
      " [ -9428.457]\n",
      " [-10935.859]\n",
      " [-11453.953]\n",
      " [-11984.322]\n",
      " [ -9994.539]\n",
      " [ -9901.754]\n",
      " [ -9592.669]\n",
      " [-11948.607]\n",
      " [ -8558.563]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final energy:\")\n",
    "print(y.get_shape())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      "tf.Tensor(\n",
      "[[-11376.758]\n",
      " [ -9429.651]\n",
      " [-10937.167]\n",
      " [-11453.006]\n",
      " [-11980.546]\n",
      " [ -9990.978]\n",
      " [ -9899.319]\n",
      " [ -9589.001]\n",
      " [-11945.698]\n",
      " [ -8551.802]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\")\n",
    "print(train_features[\"targets\"][:,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without training, the error is very large"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
